{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c07015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.2\n",
      "/Users/aaditya.paliwal/Desktop/regression_ml_end2end/.venv/lib/python3.13/site-packages/xgboost/__init__.py\n",
      "/Users/aaditya.paliwal/Desktop/regression_ml_end2end/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import sys\n",
    "print(xgb.__version__)\n",
    "print(xgb.__file__)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7ea39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaditya.paliwal/Desktop/regression_ml_end2end/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 1. Imports\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a425270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578916, 38)\n",
      "(148697, 38)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2. Loading Processed Datasets\n",
    "# ==============================================\n",
    "\n",
    "train_df = pd.read_csv(\"/Users/aaditya.paliwal/Desktop/regression_ml_end2end/data/processed/feature_engineered_train.csv\", index_col=0)\n",
    "dev_df = pd.read_csv(\"/Users/aaditya.paliwal/Desktop/regression_ml_end2end/data/processed/feature_engineered_dev.csv\", index_col=0)\n",
    "\n",
    "# Define target + features\n",
    "target = \"price\"\n",
    "X_train = train_df.drop(columns=[target])\n",
    "y_train = train_df[target]\n",
    "\n",
    "X_dev = dev_df.drop(columns=[target])\n",
    "y_dev = dev_df[target]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da6a8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 3. Define Optuna objective function with MLFlow\n",
    "# ==============================================\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define params\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    # Start MLFlow Run\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_dev)\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_dev, y_pred)))\n",
    "        mae = float(mean_absolute_error(y_dev, y_pred))\n",
    "        r2 = float(r2_score(y_dev, y_pred))\n",
    "\n",
    "        # Logging hyperparameters and metrics\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fba875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-05 18:28:07,173] A new study created in memory with name: no-name-70928930-b8e7-4a91-9283-4d5c319947fd\n",
      "[I 2026-01-05 18:28:08,776] Trial 0 finished with value: 68253.64975099656 and parameters: {'n_estimators': 114, 'max_depth': 8, 'learning_rate': 0.0891818286833785, 'subsample': 0.8522179757500077, 'colsample_bytree': 0.5515047064944292, 'min_child_weight': 8, 'gamma': 3.289194818927856, 'reg_alpha': 0.001481796247474645, 'reg_lambda': 0.9511116273334357, 'booster': 'gbtree'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 18:28:12,264] Trial 1 finished with value: 74226.45637656005 and parameters: {'n_estimators': 337, 'max_depth': 7, 'learning_rate': 0.026997726710675702, 'subsample': 0.7046831400621236, 'colsample_bytree': 0.9627887949005418, 'min_child_weight': 9, 'gamma': 4.294250301741921, 'reg_alpha': 2.8459009486911034e-07, 'reg_lambda': 2.4368425520816053, 'booster': 'gbtree'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 18:28:17,221] Trial 2 finished with value: 75386.60263213268 and parameters: {'n_estimators': 653, 'max_depth': 6, 'learning_rate': 0.21179705877286617, 'subsample': 0.6316456565415431, 'colsample_bytree': 0.5611466214079988, 'min_child_weight': 1, 'gamma': 0.5470568624780092, 'reg_alpha': 0.0030932078144591873, 'reg_lambda': 0.0002165423395786131, 'booster': 'gbtree'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 19:10:08,750] Trial 3 finished with value: 71703.50821602889 and parameters: {'n_estimators': 428, 'max_depth': 9, 'learning_rate': 0.010921510038720668, 'subsample': 0.9904128349643448, 'colsample_bytree': 0.601020719377931, 'min_child_weight': 7, 'gamma': 2.2151644871784644, 'reg_alpha': 2.9098335363846746e-07, 'reg_lambda': 0.0029233465281219813, 'booster': 'dart'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 19:25:55,426] Trial 4 finished with value: 74663.9879061415 and parameters: {'n_estimators': 436, 'max_depth': 5, 'learning_rate': 0.13412056345881962, 'subsample': 0.9255076916855516, 'colsample_bytree': 0.7509244889920625, 'min_child_weight': 1, 'gamma': 3.326682317288068, 'reg_alpha': 1.7411665011571994e-05, 'reg_lambda': 0.00046778533967573846, 'booster': 'dart'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 19:26:00,202] Trial 5 finished with value: 78920.41488058539 and parameters: {'n_estimators': 865, 'max_depth': 4, 'learning_rate': 0.023394784584872107, 'subsample': 0.7783882179462243, 'colsample_bytree': 0.8958723660224377, 'min_child_weight': 7, 'gamma': 2.805482187937912, 'reg_alpha': 0.013609849571725011, 'reg_lambda': 0.0030423159267355883, 'booster': 'gbtree'}. Best is trial 0 with value: 68253.64975099656.\n",
      "/Users/aaditya.paliwal/Desktop/regression_ml_end2end/.venv/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:26:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\", \"tree_method\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2026-01-05 19:26:06,953] Trial 6 finished with value: 124516.95464096658 and parameters: {'n_estimators': 638, 'max_depth': 9, 'learning_rate': 0.08854011195157843, 'subsample': 0.6547249881992367, 'colsample_bytree': 0.8269894569108196, 'min_child_weight': 10, 'gamma': 4.477556162616224, 'reg_alpha': 2.324948645360731e-08, 'reg_lambda': 0.00031389616248058035, 'booster': 'gblinear'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 19:32:45,940] Trial 7 finished with value: 145864.32263882598 and parameters: {'n_estimators': 325, 'max_depth': 7, 'learning_rate': 0.003488398257526519, 'subsample': 0.5214173449501363, 'colsample_bytree': 0.8875268613523477, 'min_child_weight': 4, 'gamma': 3.144015080423883, 'reg_alpha': 1.6509720944841248e-08, 'reg_lambda': 0.0013316984491611593, 'booster': 'dart'}. Best is trial 0 with value: 68253.64975099656.\n",
      "/Users/aaditya.paliwal/Desktop/regression_ml_end2end/.venv/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:32:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\", \"tree_method\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2026-01-05 19:32:56,721] Trial 8 finished with value: 125081.21774727109 and parameters: {'n_estimators': 982, 'max_depth': 4, 'learning_rate': 0.27703511132731123, 'subsample': 0.7368090908580702, 'colsample_bytree': 0.7767648388483672, 'min_child_weight': 7, 'gamma': 4.531766184872313, 'reg_alpha': 0.0002829063358793515, 'reg_lambda': 0.500636477554164, 'booster': 'gblinear'}. Best is trial 0 with value: 68253.64975099656.\n",
      "/Users/aaditya.paliwal/Desktop/regression_ml_end2end/.venv/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [19:32:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\", \"subsample\", \"tree_method\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2026-01-05 19:33:06,193] Trial 9 finished with value: 125485.22916745613 and parameters: {'n_estimators': 864, 'max_depth': 7, 'learning_rate': 0.06030150441075068, 'subsample': 0.849162239347734, 'colsample_bytree': 0.8297300062593929, 'min_child_weight': 7, 'gamma': 1.2233871363755944, 'reg_alpha': 4.972933818915599e-08, 'reg_lambda': 1.645476838612067, 'booster': 'gblinear'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 19:33:08,228] Trial 10 finished with value: 332879.3490156765 and parameters: {'n_estimators': 104, 'max_depth': 9, 'learning_rate': 0.00125786269262693, 'subsample': 0.8575105744783479, 'colsample_bytree': 0.6615485044395328, 'min_child_weight': 4, 'gamma': 1.852066734325014, 'reg_alpha': 2.369628751670013, 'reg_lambda': 1.789122918367774e-08, 'booster': 'gbtree'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 19:34:10,612] Trial 11 finished with value: 184085.18872389605 and parameters: {'n_estimators': 122, 'max_depth': 10, 'learning_rate': 0.006781602165649543, 'subsample': 0.9912576690582436, 'colsample_bytree': 0.5070053439310906, 'min_child_weight': 8, 'gamma': 1.9403393438939969, 'reg_alpha': 7.2889142155632e-06, 'reg_lambda': 0.04984837416511455, 'booster': 'dart'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 19:37:26,532] Trial 12 finished with value: 106874.64851303706 and parameters: {'n_estimators': 224, 'max_depth': 9, 'learning_rate': 0.0073338022630670945, 'subsample': 0.9765183163539402, 'colsample_bytree': 0.6424623708170754, 'min_child_weight': 5, 'gamma': 3.602683816605332, 'reg_alpha': 0.160210505824043, 'reg_lambda': 3.867413528195629e-06, 'booster': 'dart'}. Best is trial 0 with value: 68253.64975099656.\n",
      "[I 2026-01-05 19:37:32,125] Trial 13 finished with value: 67943.97889597258 and parameters: {'n_estimators': 516, 'max_depth': 8, 'learning_rate': 0.04339896173750895, 'subsample': 0.8702954761680367, 'colsample_bytree': 0.6317478812010022, 'min_child_weight': 10, 'gamma': 2.2005211813104624, 'reg_alpha': 1.1004855582527181e-05, 'reg_lambda': 0.03112611143481403, 'booster': 'gbtree'}. Best is trial 13 with value: 67943.97889597258.\n",
      "[I 2026-01-05 19:37:37,908] Trial 14 finished with value: 68886.17955204943 and parameters: {'n_estimators': 543, 'max_depth': 8, 'learning_rate': 0.042617091516721176, 'subsample': 0.8457454389791298, 'colsample_bytree': 0.6682836482064438, 'min_child_weight': 10, 'gamma': 0.03217352794742334, 'reg_alpha': 8.923934189220459e-05, 'reg_lambda': 0.07096668302276604, 'booster': 'gbtree'}. Best is trial 13 with value: 67943.97889597258.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  15\n",
      "Best params: {'n_estimators': 516, 'max_depth': 8, 'learning_rate': 0.04339896173750895, 'subsample': 0.8702954761680367, 'colsample_bytree': 0.6317478812010022, 'min_child_weight': 10, 'gamma': 2.2005211813104624, 'reg_alpha': 1.1004855582527181e-05, 'reg_lambda': 0.03112611143481403, 'booster': 'gbtree'}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 4. Run Optuna study with MLflow\n",
    "# ==============================================\n",
    "\n",
    "# Force MLflow to always use the root project mlruns folder\n",
    "\n",
    "mlflow.set_tracking_uri(\"/Users/aaditya.paliwal/Desktop/regression_ml_end2end/mlruns\")\n",
    "mlflow.set_experiment(\"xgboost_optuna_housing\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c17facbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final tuned model performance:\n",
      "MAE: 30985.11416698783\n",
      "RMSE: 67908.66968863898\n",
      "R²: 0.9643543050601973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/05 20:48:29 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 5. Train final model with best params and log to MLflow\n",
    "# ==============================================\n",
    "best_params = study.best_trial.params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_dev)\n",
    "\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_dev, y_pred))\n",
    "r2 = r2_score(y_dev, y_pred)\n",
    "\n",
    "print(\"Final tuned model performance:\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Log final model\n",
    "with mlflow.start_run(run_name=\"best_xgboost_model\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=best_model,\n",
    "        name=\"model\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fee13bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xgboost.sklearn.XGBRegressor'>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(type(best_model))\n",
    "print(hasattr(best_model, \"_estimator_type\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1922b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regression-ml-end2end",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
